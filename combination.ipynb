{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from C3D_model import C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from C3D_model import C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C3D()\n",
    "model.load_state_dict(torch.load('c3d.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = torch.nn.Sequential(*(list(model.children())[:-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=8192, out_features=4096, bias=True),\n",
       " Linear(in_features=4096, out_features=4096, bias=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[-6:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8192, out_features=4096, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = torch.nn.Sequential(*(list(model.children())[:-6]))\n",
    "feature_extractor_head = torch.nn.Sequential(*(list(model.children())[-6:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3D_CNN_LIST = list(model.children())[:-6]\n",
    "C3D_ANN_LIST = list(model.children())[-6:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=8192, out_features=4096, bias=True),\n",
       " Linear(in_features=4096, out_features=4096, bias=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C3D_ANN_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network as described in [1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(C3D_CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = C3D_CNN_LIST[0]\n",
    "        self.pool1 = C3D_CNN_LIST[1]\n",
    "\n",
    "        self.conv2 = C3D_CNN_LIST[2]\n",
    "        self.pool2 = C3D_CNN_LIST[3]\n",
    "\n",
    "        self.conv3a = C3D_CNN_LIST[4]\n",
    "        self.conv3b = C3D_CNN_LIST[5]\n",
    "        self.pool3 = C3D_CNN_LIST[6]\n",
    "\n",
    "        self.conv4a = C3D_CNN_LIST[7]\n",
    "        self.conv4b = C3D_CNN_LIST[8]\n",
    "        self.pool4 = C3D_CNN_LIST[9]\n",
    "\n",
    "        self.conv5a = C3D_CNN_LIST[10]\n",
    "        self.conv5b = C3D_CNN_LIST[11]\n",
    "        self.pool5 = C3D_CNN_LIST[12]\n",
    "\n",
    "        #self.fc6 = nn.Linear(8192, 4096)\n",
    "        #self.fc7 = nn.Linear(4096, 4096)\n",
    "        #self.fc8 = nn.Linear(4096, 487)\n",
    "\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #print('input', x.shape)\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "        #print('layer 1', h.shape)\n",
    "\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "        #print('layer 2', h.shape)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "        #print('layer 3', h.shape)\n",
    "\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "        #print('layer 4', h.shape)\n",
    "\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "        #print('layer 5', h.shape)\n",
    "\n",
    "        #h = h.view(-1, 8192)\n",
    "        #h = self.relu(self.fc6(h))\n",
    "        #h = self.dropout(h)\n",
    "        #h = self.relu(self.fc7(h))\n",
    "        #h = self.dropout(h)\n",
    "        #print('layer 6', h.shape)\n",
    "\n",
    "        #logits = self.fc8(h)\n",
    "        #probs = self.softmax(logits)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D_ANN(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network as described in [1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(C3D_ANN, self).__init__()\n",
    "\n",
    "        self.fc6 = C3D_ANN_LIST[0]\n",
    "        self.fc7 = C3D_ANN_LIST[1]\n",
    "\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h = h.view(-1, 8192)\n",
    "        h = self.relu(self.fc6(x))\n",
    "        #h = self.dropout(h)\n",
    "        #h = self.relu(self.fc7(h))\n",
    "        #h = self.dropout(h)\n",
    "\n",
    "        #logits = self.fc8(h)\n",
    "        #probs = self.softmax(logits)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(dict2):\n",
    "    i = 0\n",
    "    dict = {}\n",
    "    for i in range(len(dict2)):\n",
    "        if str(i) in dict2:\n",
    "            if dict2[str(i)].shape == (0, 0):\n",
    "                dict[str(i)] = dict2[str(i)]\n",
    "            else:\n",
    "                weights = dict2[str(i)][0]\n",
    "                weights2 = []\n",
    "                for weight in weights:\n",
    "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
    "                        weights2.append(weight[0])\n",
    "                    else:\n",
    "                        weights2.append(weight)\n",
    "                dict[str(i)] = weights2\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(weight_path, layer):\n",
    "    # To load the weights from file\n",
    "    dict2 = loadmat(weight_path)\n",
    "    weights = conv_dict(dict2)\n",
    "    # TO get the required weight\n",
    "    weight = np.array(weights[layer])\n",
    "    shape = weight[0].shape\n",
    "    weight = np.reshape(weight[0], (shape[1], shape[0]))\n",
    "    weight = torch.tensor(weight)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomaly_ann(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(anomaly_ann, self).__init__()\n",
    "        weights = './weights_L1L2.mat'\n",
    "        self.layer1 = nn.Linear(4096, 512)\n",
    "        self.layer1.weight.data = get_weight(weights, '0')\n",
    "\n",
    "        self.layer2 = nn.Linear(512, 32)\n",
    "        self.layer2.weight.data = get_weight(weights, '2')\n",
    "\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.layer3.weight.data = get_weight(weights, '4')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"x\", x.shape)\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        #out = (out-out.mean())/(out.max()-out.mean())\n",
    "        #print(\"after vgg\", out.shape)\n",
    "        out = self.layer2(out)\n",
    "        #out = (out-out.mean())/(out.max()-out.mean())\n",
    "        #print(\"after transpose\", out.shape)\n",
    "        out = self.layer3(out)\n",
    "        #print(\"after output layer\", out.shape)\n",
    "        return out\n",
    "        #return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomaly_detector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(anomaly_detector, self).__init__()\n",
    "        self.feature_extractor = C3D_CNN()\n",
    "        self.feature_extractor_head = C3D_ANN()\n",
    "        self.ann = anomaly_ann()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"x\", x.shape)\n",
    "        out = self.feature_extractor(x)\n",
    "        \n",
    "        out = out.view(-1, 8192)\n",
    "        out = self.feature_extractor_head(out)\n",
    "        out = self.ann(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = anomaly_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anomaly_detector(\n",
       "  (feature_extractor): C3D_CNN(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (relu): ReLU()\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       "  (feature_extractor_head): C3D_ANN(\n",
       "    (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "    (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       "  (ann): anomaly_ann(\n",
       "    (layer1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (layer2): Linear(in_features=512, out_features=32, bias=True)\n",
       "    (layer3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocc(arr):\n",
    "    blocc = np.array([resize(frame, output_shape=(112, 200), preserve_range=True) for frame in arr])\n",
    "\n",
    "    blocc = blocc[:, :, 44:44+112, :]\n",
    "    blocc = blocc.transpose(3, 0, 1, 2)  # ch, fr, h, w\n",
    "    blocc = np.expand_dims(blocc, axis=0)  # batch axis\n",
    "    #blocc = (blocc-blocc.mean())/(blocc.max()-blocc.mean())\n",
    "    blocc = np.float32(blocc)\n",
    "    blocc = torch.from_numpy(blocc)\n",
    "    return blocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(video, model):\n",
    "    cap = cv2.VideoCapture(video) \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "      print(\"Error opening video stream or file\")\n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,30)\n",
    "    fontScale              = 0.4\n",
    "    fontColor              = (255,0,0)\n",
    "    lineType               = 2\n",
    "    frames = 0\n",
    "    \n",
    "    # Read until video is completed\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    arr = []\n",
    "    score = 0\n",
    "    message = \"\"\n",
    "    while(cap.isOpened()):\n",
    "      # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if(i<32):\n",
    "            arr.append(frame)\n",
    "            i+=1\n",
    "        else:\n",
    "            i = 0\n",
    "            arr = []\n",
    "            print(message)\n",
    "\n",
    "        if (ret == True):\n",
    "            if(len(arr) == 32):\n",
    "                frames+=32\n",
    "                X = get_blocc(arr)\n",
    "                #print(X.mean(), sep='\\r', end='\\r')\n",
    "                prediction = model(X)\n",
    "                score = prediction.data.cpu().numpy()\n",
    "                score = str(score)\n",
    "                end_time = time.time()-start_time\n",
    "                frame_rate = int(frames/end_time)\n",
    "                message = \"framerate = {}, score = {}, frame_id = {}\".format(frame_rate, score, i)\n",
    "            cv2.putText(frame, message, \n",
    "                        bottomLeftCornerOfText, \n",
    "                        font, \n",
    "                        fontScale,\n",
    "                        fontColor,\n",
    "                        lineType)\n",
    "            cv2.imshow('Frame',frame)\n",
    "            #print(message, sep='\\r', end = '\\r')\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_file = '/home/nevin/nevin/datasets/anomaly detection/assault/Assault015_x264.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nevin/anaconda3/envs/pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/nevin/anaconda3/envs/pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framerate = 7, score = [[3.108469 ]\n",
      " [3.1666684]], frame_id = 32\n",
      "framerate = 7, score = [[5.2511907]\n",
      " [4.6372533]], frame_id = 32\n",
      "framerate = 7, score = [[6.3259788]\n",
      " [4.647742 ]], frame_id = 32\n",
      "framerate = 7, score = [[3.9562206]\n",
      " [3.7307994]], frame_id = 32\n",
      "framerate = 7, score = [[3.8554177]\n",
      " [2.9614887]], frame_id = 32\n",
      "framerate = 7, score = [[6.0859847]\n",
      " [5.5639625]], frame_id = 32\n",
      "framerate = 7, score = [[6.204521 ]\n",
      " [2.7206492]], frame_id = 32\n",
      "framerate = 7, score = [[5.104228 ]\n",
      " [4.0239744]], frame_id = 32\n",
      "framerate = 7, score = [[3.9461088]\n",
      " [3.7143111]], frame_id = 32\n",
      "framerate = 7, score = [[3.5962553]\n",
      " [4.4732766]], frame_id = 32\n",
      "framerate = 7, score = [[3.642368 ]\n",
      " [4.7454677]], frame_id = 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-899f8216a080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-7091ae544583>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(video, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Press Q on keyboard to  exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# Break the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict(vid_file, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
